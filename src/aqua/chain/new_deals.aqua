module NewDeals declares poll_new_deals

import or, not from "@fluencelabs/aqua-lib/binary.aqua"
import Spell, TriggerConfig from "@fluencelabs/spell/spell_service.aqua"

import FluenceAuroraConnector, DealCreated from "services.aqua"

import AuroraInfo from "aurora.aqua"
import deal_log, spell_log, get_counter, get_string from "../fluence/spell.aqua"
import is_worker_created from "../fluence/worker.aqua"
import Json from "../fluence/peer.aqua"
import join_deal from "../decider/join_deal.aqua"
import get_latest from "../chain/blocks.aqua"
import SpellId from "../types.aqua"

-- `last seen block` is a block for which all events have been processed
func get_last_seen(spell_id: SpellId) -> ?string:
    Spell spell_id
    last_seen, ok <- get_string(spell_id, "last_seen_block")
    <- last_seen

func save_last_seen(spell_id: SpellId, hex: string):
    Spell spell_id
    r <- Spell.set_string("last_seen_block", hex)
    if r.success == false:
        spell_log(spell_id, ["error saving last_seen_block", r.error])

-- read `from_block` from KV
-- `from_block` is usually set as a port of `init data` for `decider`
func get_from_block(spell_id: SpellId) -> string:
    Spell spell_id
    from_block: *string

    maybe_from_block, ok <- get_string(spell_id, "from_block")
    if maybe_from_block == nil:
        -- if `from_block` is not set, use "latest" as default
        from_block <<- "latest"
    else:
        from_block <<- maybe_from_block!

    <- from_block!

-- Evaluate 'latest' or 'earliest' in the `from_block` to actual hex value
-- "latest" => latest block on chain
-- "earliest" => 0x0
func evaluate_from_block(spell_id: SpellId, chain: AuroraInfo) -> ?string:
    left: ?string
    from_block <- get_from_block(spell_id)
    if from_block == "latest":
        latest <- get_latest(spell_id, chain)
        if latest != nil:
            left <<- latest!
        -- if `get_latest` fails, there's nothing we can do, so return `nil`
    else:
        if from_block == "earliest":
            left <<- "0x0"
        else:
            left <<- from_block
    <- left

-- initialize `last seen` to the value of `from_block`, so that polls start from that value as a left boundary
-- NOTE: `from_block` is passed as a part of decider's `init data`
func initialize_last_seen(spell_id: SpellId, chain: AuroraInfo) -> ?string:
    from_block <- evaluate_from_block(spell_id, chain)
    if from_block != nil:
        save_last_seen(spell_id, from_block!)
    <- from_block

-- return a value to use as a left boundary in `eth_newLogs`
-- it usually equals to `last seen block`, except on first iteration it is equal to evaluated `from_block`
func get_left_boundary(spell_id: SpellId, chain: AuroraInfo) -> ?string:
    left: ?string

    -- load "last seen" block number
    -- `last seen block` is initialized to the first `left boundary` this function returns
    -- After that, `last seen block` is set to the block number of every next processed Log
    maybe_last_seen <- get_last_seen(spell_id)
    if maybe_last_seen == nil:
        -- When have not yet seen any blocks, initialize `last seen` to `from_block`
        last_seen <- initialize_last_seen(spell_id, chain)
        if last_seen != nil:
            left <<- last_seen!
        -- if `initialize_last_seen` returned `nil`, just bubble that `nil`
    else:
        left <<- maybe_last_seen!
    <- left

func join_deals(spell_id: SpellId, logs: []DealCreated):
    Spell spell_id

    -- TODO: I assume that `logs` are sorted by `block_number`. Is that a correct assumption?
    for log <- logs:
        deal_id = log.info.deal_id
        if is_worker_created(spell_id, deal_id):
            deal_log(spell_id, deal_id, "worker for deal is already created")
        else:
            -- Use `log.block_number - 1` as a `last seen block`
            -- Can not use `log.block_number` because it is unknown if there are more events from that block in `logs`
            -- If a log from block N is received, then the whole `N-1` block was processed, so save it as the `last seen`
            prev_block <- FluenceAuroraConnector.hex_sub(log.block_number, 1)
            if prev_block.success:
                join_deal(spell_id, log)
                -- Set `last seen block` to the `log.block_number - 1`
                -- This way, if particle has timed out during process of a log, `last seen block` would not be updated
                -- And we will try all events from that block again
                save_last_seen(spell_id, prev_block.diff!)

func poll_logs(spell_id: SpellId, chain: AuroraInfo, left: string) -> []DealCreated:
    result <- FluenceAuroraConnector.poll_deal_created(chain.api_endpoint, chain.address, left)
    if result.success == false:
        spell_log(spell_id, ["error polling deal created events", result.error])

    logs = result.result
    co spell_log(spell_id, ["number of logs returned by poll:", logs.length])

    <- logs

func get_logs(spell_id: SpellId, chain: AuroraInfo) -> []DealCreated:
    Spell spell_id
    logs: ?[]DealCreated

    -- retrieve block number to poll from
    left <- get_left_boundary(spell_id, chain)
    if left != nil:
        logs <<- poll_logs(spell_id, chain, left!)
    else:
        -- if it's not possible to retrieve `left boundary`, then it's not possible to `poll_logs`
        spell_log(spell_id, ["get_left_boundary returns nil, unable to proceed"])
        logs <<- nil
    <- logs!

func poll_new_deals(spell_id: SpellId, chain: AuroraInfo):
    logs <- get_logs(spell_id, chain)
    if logs != nil:
        join_deals(spell_id, logs)
